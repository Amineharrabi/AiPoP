name: Incremental Data Update

on:
  schedule:
    - cron: "0 */6 * * *" # Run every 6 hours (more reasonable than 10 min)
  workflow_dispatch: # Allow manual trigger

jobs:
  update-data:
    runs-on: ubuntu-latest
    environment: production

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Need full history for git operations

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download existing database
        continue-on-error: true
        run: |
          # Try to download existing database from latest release or artifacts
          if [ -f "data/warehouse/ai_bubble.duckdb" ]; then
            echo "Database already exists"
          else
            echo "No existing database found - will need full setup"
          fi

      - name: Set up environment variables
        run: |
          echo "PYTHONUNBUFFERED=1" >> $GITHUB_ENV
        env:
          SEC_API_KEY: ${{ secrets.SEC_API_KEY }}
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
          HF_ACCESS_TOKEN: ${{ secrets.HF_ACCESS_TOKEN }}
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}

      - name: Initialize database if needed
        run: |
          if [ ! -f "data/warehouse/ai_bubble.duckdb" ]; then
            echo "Initializing database..."
            python setup/setup_duckdb.py
          else
            echo "Database exists, skipping initialization"
          fi
        env:
          SEC_API_KEY: ${{ secrets.SEC_API_KEY }}
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
          HF_ACCESS_TOKEN: ${{ secrets.HF_ACCESS_TOKEN }}
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}

      - name: Ingest new data
        run: |
          echo "Ingesting new data from all sources..."

          # Run all ingest scripts (they should be idempotent)
          python ingest/ingest_yfinance.py || echo "YFinance ingest had issues"
          python ingest/ingest_news.py || echo "News ingest had issues"
          python ingest/ingest_reddit.py || echo "Reddit ingest had issues"
          python ingest/ingest_sec.py || echo "SEC ingest had issues"
          python ingest/ingest_github_hf.py || echo "GitHub/HF ingest had issues"
        continue-on-error: true
        env:
          SEC_API_KEY: ${{ secrets.SEC_API_KEY }}
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
          GITHUB_TOKEN: ${{ secrets.GH_PAT }}
          HF_ACCESS_TOKEN: ${{ secrets.HF_ACCESS_TOKEN }}
          NEWS_API_KEY: ${{ secrets.NEWS_API_KEY }}

      - name: Load new data to warehouse
        run: |
          echo "Loading new staging data to warehouse..."
          python setup/load_warehouse.py

      - name: Compute features for new data
        run: |
          echo "Computing features..."
          python setup/compute_features.py

      - name: Run incremental index update
        run: |
          echo "Running incremental update (only new data points)..."
          python setup/incremental_update.py

      - name: Detect bubble patterns
        run: |
          echo "Running bubble detection..."
          python setup/detect_bubble.py
        continue-on-error: true

      - name: Check for data changes
        id: check-updates
        run: |
          # Check if database was modified
          if [ -f "data/warehouse/ai_bubble.duckdb" ]; then
            # Count size change
            SIZE=$(stat -f%z "data/warehouse/ai_bubble.duckdb" 2>/dev/null || stat -c%s "data/warehouse/ai_bubble.duckdb" 2>/dev/null || echo "0")
            echo "size=$SIZE" >> $GITHUB_OUTPUT
            
            # Check git status
            CHANGED=$(git status --porcelain data/warehouse/ai_bubble.duckdb | wc -l)
            echo "changed=$CHANGED" >> $GITHUB_OUTPUT
            
            echo "Database size: $SIZE bytes"
            echo "Changed files: $CHANGED"
          else
            echo "changed=0" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push database
        if: steps.check-updates.outputs.changed != '0'
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

          git remote set-url origin https://x-access-token:$$ {{ secrets.GH_PAT }}@github.com/ $${{ github.repository }}.git

          # Stage database file
          git add data/warehouse/ai_bubble.duckdb

          # Also add any new raw/staging files (optional)
          git add data/raw/ data/staging/ || true

          # Create commit
          TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
          git commit -m "üìä Data update: $TIMESTAMP" \
                     -m "Updated database with latest data" \
                     -m "Size: ${{ steps.check-updates.outputs.size }} bytes" || exit 0

          # Push changes
          git push || {
            echo "Push failed, trying to pull and rebase..."
            git pull --rebase origin main
            git push
          }

      - name: Generate summary
        if: always()
        run: |
          echo "## Data Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** $(date +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "- **Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY

          if [ -f "data/warehouse/ai_bubble.duckdb" ]; then
            # Get database stats using Python
            python3 << 'EOF' >> $GITHUB_STEP_SUMMARY
          import duckdb
          import os
          try:
              conn = duckdb.connect('data/warehouse/ai_bubble.duckdb', read_only=True)
              
              # Get data points
              result = conn.execute("SELECT MIN(date) as first, MAX(date) as last, COUNT(*) as total FROM bubble_metrics").fetchone()
              if result:
                  print(f"- **Date Range:** {result[0]} to {result[1]}")
                  print(f"- **Total Data Points:** {result[2]}")
              
              # Get latest values
              latest = conn.execute("SELECT hype_index, reality_index, hype_reality_gap FROM bubble_metrics ORDER BY date DESC LIMIT 1").fetchone()
              if latest:
                  print(f"- **Latest Hype Index:** {latest[0]:.4f}")
                  print(f"- **Latest Reality Index:** {latest[1]:.4f}")
                  print(f"- **Hype-Reality Gap:** {latest[2]:.4f}")
              
              conn.close()
          except Exception as e:
              print(f"- **Error getting stats:** {e}")
          EOF
                    fi
                
                - name: Create issue on failure
                  if: failure()
                  uses: actions/github-script@v6
                  with:
                    script: |
                      const title = '‚ö†Ô∏è Data Update Failed';
                      const body = `The incremental data update workflow failed at ${new Date().toISOString()}.
                      
                      **Workflow Run:** [View Details](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})
                      
                      Please check the logs and investigate the issue.
                      
                      Common issues:
                      - API rate limits
                      - Network connectivity
                      - Database corruption
                      - Missing dependencies
                      `;
                      
                      await github.rest.issues.create({
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        title,
                        body,
                        labels: ['automated', 'data-update-failed', 'bug']
                      });
